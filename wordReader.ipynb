{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 206, 2360), (1, 3231, 2308), (2, 1695, 2286), (3, 952, 1829), (4, 956, 2341), (5, 2479, 2279), (6, 199, 1841), (7, 2472, 1787), (8, 3201, 1791), (9, 1705, 1790), (10, 205, 1313), (11, 946, 1277), (12, 2491, 1263), (13, 3208, 1251), (14, 970, 734), (15, 236, 758), (16, 2502, 701), (17, 3201, 694), (18, 218, 196), (19, 1702, 715), (20, 1733, 1260), (21, 1701, 183), (22, 3211, 171), (23, 966, 192), (24, 2439, 159)]\n",
      "[(24, 2439, 159), (22, 3211, 171), (21, 1701, 183), (23, 966, 192), (18, 218, 196), (17, 3201, 694), (16, 2502, 701), (19, 1702, 715), (14, 970, 734), (15, 236, 758), (13, 3208, 1251), (20, 1733, 1260), (12, 2491, 1263), (11, 946, 1277), (10, 205, 1313), (7, 2472, 1787), (9, 1705, 1790), (8, 3201, 1791), (3, 952, 1829), (6, 199, 1841), (5, 2479, 2279), (2, 1695, 2286), (1, 3231, 2308), (4, 956, 2341), (0, 206, 2360)]\n",
      "[(18, 218, 196), (23, 966, 192), (21, 1701, 183), (24, 2439, 159), (22, 3211, 171), (15, 236, 758), (14, 970, 734), (19, 1702, 715), (16, 2502, 701), (17, 3201, 694), (10, 205, 1313), (11, 946, 1277), (20, 1733, 1260), (12, 2491, 1263), (13, 3208, 1251), (6, 199, 1841), (3, 952, 1829), (9, 1705, 1790), (7, 2472, 1787), (8, 3201, 1791), (0, 206, 2360), (4, 956, 2341), (2, 1695, 2286), (5, 2479, 2279), (1, 3231, 2308)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "img_board = cv2.imread('assets/5x5.jpg')\n",
    "img_board = cv2.rotate(img_board, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "img_board_gray = cv2.cvtColor(img_board, cv2.COLOR_BGR2GRAY)\n",
    "img_h,img_w = img_board_gray.shape\n",
    "background_thresh = img_board_gray[0][0]\n",
    "ADD_THRESH = 90\n",
    "blur = cv2.GaussianBlur(img_board_gray,(5,5),0)\n",
    "total_thresh = background_thresh + ADD_THRESH\n",
    "_,thresh_img = cv2.threshold(blur,total_thresh,255,cv2.THRESH_BINARY)\n",
    "contours, hier = cv2.findContours(thresh_img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "top_25_contours = sorted(contours, key=lambda x : cv2.contourArea(x) if cv2.contourArea(x) < (img_h * img_w)/25 else 0,reverse=True)[:25]\n",
    "\n",
    "# sort x and y later\n",
    "coords_and_index = []\n",
    "for i,contour in enumerate(top_25_contours):\n",
    "    x, y, _, _ = cv2.boundingRect(contour)\n",
    "    coords_and_index.append((i,x,y))\n",
    "print(coords_and_index)\n",
    "sorted_y = sorted(coords_and_index,key=lambda x:x[2])\n",
    "print(sorted_y)\n",
    "for i in range(5):\n",
    "    sorted_y[5 * i:5* (i + 1)] = sorted(sorted_y[5 * i:5* (i + 1)], key=lambda x:x[1])\n",
    "top_25_sorted = [top_25_contours[i[0]] for i in sorted_y]\n",
    "print(sorted_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_img = cv2.cvtColor(thresh_img, cv2.COLOR_BGR2RGB)\n",
    "cv2.drawContours(print_img, top_25_contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "fontScale = 10\n",
    "color = (255, 0, 0)\n",
    "thickness = 5\n",
    "for i, place in enumerate(sorted_y):  \n",
    "    cv2.putText(print_img, str(i), (place[1] + 10,place[2] + 10), font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "imS = cv2.resize(print_img, (960, 540)) \n",
    "cv2.imshow('Contours', imS)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(image, pts, w, h):\n",
    "    \"\"\"Flattens an image of a card into a top-down 200x300 perspective.\n",
    "    Returns the flattened, re-sized, grayed image.\n",
    "    See www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/\"\"\"\n",
    "    temp_rect = np.zeros((4,2), dtype = \"float32\")\n",
    "    \n",
    "    s = np.sum(pts, axis = 2)\n",
    "\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis = -1)\n",
    "    tr = pts[np.argmin(diff)]\n",
    "    bl = pts[np.argmax(diff)]\n",
    "\n",
    "    # Need to create an array listing points in order of\n",
    "    # [top left, top right, bottom right, bottom left]\n",
    "    # before doing the perspective transform\n",
    "\n",
    "    if w <= 0.8*h: # If card is vertically oriented\n",
    "        temp_rect[0] = tl\n",
    "        temp_rect[1] = tr\n",
    "        temp_rect[2] = br\n",
    "        temp_rect[3] = bl\n",
    "\n",
    "    if w >= 1.2*h: # If card is horizontally oriented\n",
    "        temp_rect[0] = bl\n",
    "        temp_rect[1] = tl\n",
    "        temp_rect[2] = tr\n",
    "        temp_rect[3] = br\n",
    "\n",
    "    # If the card is 'diamond' oriented, a different algorithm\n",
    "    # has to be used to identify which point is top left, top right\n",
    "    # bottom left, and bottom right.\n",
    "    \n",
    "    if w > 0.8*h and w < 1.2*h: #If card is diamond oriented\n",
    "        # If furthest left point is higher than furthest right point,\n",
    "        # card is tilted to the left.\n",
    "        if pts[1][0][1] <= pts[3][0][1]:\n",
    "            # If card is titled to the left, approxPolyDP returns points\n",
    "            # in this order: top right, top left, bottom left, bottom right\n",
    "            temp_rect[0] = pts[1][0] # Top left\n",
    "            temp_rect[1] = pts[0][0] # Top right\n",
    "            temp_rect[2] = pts[3][0] # Bottom right\n",
    "            temp_rect[3] = pts[2][0] # Bottom left\n",
    "\n",
    "        # If furthest left point is lower than furthest right point,\n",
    "        # card is tilted to the right\n",
    "        if pts[1][0][1] > pts[3][0][1]:\n",
    "            # If card is titled to the right, approxPolyDP returns points\n",
    "            # in this order: top left, bottom left, bottom right, top right\n",
    "            temp_rect[0] = pts[0][0] # Top left\n",
    "            temp_rect[1] = pts[3][0] # Top right\n",
    "            temp_rect[2] = pts[2][0] # Bottom right\n",
    "            temp_rect[3] = pts[1][0] # Bottom left\n",
    "            \n",
    "        \n",
    "    maxWidth = 200\n",
    "    maxHeight = 300\n",
    "\n",
    "    # Create destination array, calculate perspective transform matrix,\n",
    "    # and warp card image\n",
    "    dst = np.array([[0,0],[maxWidth-1,0],[maxWidth-1,maxHeight-1],[0, maxHeight-1]], np.float32)\n",
    "    M = cv2.getPerspectiveTransform(temp_rect,dst)\n",
    "    warp = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    warp = cv2.cvtColor(warp,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "\n",
    "    return warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(top_25_sorted):\n",
    "    words = []\n",
    "    for cont in top_25_sorted:\n",
    "        peri = cv2.arcLength(cont,True)\n",
    "        approx = cv2.approxPolyDP(cont,0.01*peri,True)\n",
    "        pts = np.float32(approx)\n",
    "        corner_pts = pts\n",
    "\n",
    "        x,y,w,h = cv2.boundingRect(cont)\n",
    "        width, height = w, h\n",
    "\n",
    "        average = np.sum(pts, axis=0)/len(pts)\n",
    "        cent_x = int(average[0][0])\n",
    "        cent_y = int(average[0][1])\n",
    "        center = [cent_x, cent_y]\n",
    "\n",
    "        warp = cv2.rotate(flattener(img_board, pts, w, h),cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        cropped_img = warp[warp.shape[0]//2:][:]\n",
    "        blur = cv2.GaussianBlur(cropped_img, (3,3), 0)\n",
    "        contrast = cv2.convertScaleAbs(blur, alpha=2, beta=0)\n",
    "        thresh = cv2.threshold(contrast, 0, 255, cv2.THRESH_BINARY_INV  + cv2.THRESH_OTSU)[1]\n",
    "        words.append(pytesseract.image_to_string(thresh, lang='eng', config='--psm 6').strip())\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOUL',\n",
       " 'HAM',\n",
       " 'SPRING',\n",
       " 'SUB',\n",
       " 'STOCK',\n",
       " 'SEAL',\n",
       " 'NUT',\n",
       " 'HIMALAYAS',\n",
       " 'TAP',\n",
       " 'FILM',\n",
       " 'POINT',\n",
       " 'GLOVE',\n",
       " 'WAKE',\n",
       " 'SHARK',\n",
       " 'CAST',\n",
       " 'DOCTOR',\n",
       " 'JAM',\n",
       " 'CAR',\n",
       " 'DIAMOND',\n",
       " 'NURSE',\n",
       " 'PIE',\n",
       " 'PIANO',\n",
       " 'ROBOT',\n",
       " 'WASHER',\n",
       " 'LAB']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_words(top_25_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
